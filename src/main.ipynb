{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nltk import word_tokenize\n",
    "from nltk import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# read data from tables\n",
    "apis_df = pd.read_csv(\"../datasets/apis.csv\", usecols = [0, 1, 2, 3])\n",
    "mashups_df = pd.read_csv(\"../datasets/mashups.csv\", usecols = [0, 1, 2, 3, 4])\n",
    "\n",
    "# create text filter list of English stopwords and special characters\n",
    "text_filter = list(stopwords.words(\"english\"))\n",
    "special_characters = [\",\", \"/\", \"-\", \".\", \";\"]\n",
    "for char in special_characters:\n",
    "  text_filter.append(char)\n",
    "\n",
    "# initialize text stemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "# tokenize, apply filter to, and stem text\n",
    "def text_filter_function(text):\n",
    "  result = \"\"\n",
    "  tokens = word_tokenize(str(text))\n",
    "  for token in tokens:\n",
    "    if token not in text_filter:\n",
    "      result += porter.stem(token.lower())\n",
    "      result += \" \"\n",
    "  return result\n",
    "\n",
    "# process the description column to create new bag of words column\n",
    "apis_df[\"description_words\"] = apis_df[\"description\"].apply(text_filter_function)\n",
    "# mashups_df[\"description_words\"] = mashups_df[\"description\"].apply(text_filter_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf = TfidfVectorizer(analyzer = str.split)\n",
    "api_description_matrix = tf_idf.fit_transform(apis_df[\"description_words\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 10 recommended APIs and their cosine similarity score for API: Microsoft Bing Maps API is:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Bing Static Maps API', 0.5878079074616477),\n",
       " ('Bing Maps Location Data API', 0.4769642664039478),\n",
       " ('Bing Maps API', 0.4344878866859619),\n",
       " ('South African YellowPages Maps API', 0.42634012841653235),\n",
       " ('TomTom Maps API', 0.420441990775066),\n",
       " ('NAC Real-time Mapping API', 0.4021403497873083),\n",
       " ('Map Data Services QuickMap API', 0.3924264814192068),\n",
       " ('Google Maps for Work API', 0.3890421173426575),\n",
       " ('Google Maps Flash API', 0.3887042650391142),\n",
       " ('Ericsson Web Maps API', 0.3841654058048892)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# recommend the top k related APIs to a given API\n",
    "def recommend_apis(api_id, k = 10):\n",
    "  recommendations = []\n",
    "  top_k_recommendations = []\n",
    "\n",
    "  # for all API entries\n",
    "  for i in range(api_description_matrix.shape[0]):\n",
    "    # if it's not the same as selected API\n",
    "    if i != api_id:\n",
    "      # calculate the cosine similarity between all other APIs and selected API\n",
    "      cos_sim_score_i = cosine_similarity(api_description_matrix[api_id], api_description_matrix[i])[0][0]\n",
    "      # append index and related cosine similarity score\n",
    "      top_k_recommendations.append((i, cos_sim_score_i))\n",
    "\n",
    "  # sort the array descending using cosine similarity score, and pick the first k elements\n",
    "  top_k_recommendations = sorted(top_k_recommendations, reverse = True, key = lambda x: x[1])[:k]\n",
    "\n",
    "  for i in top_k_recommendations:\n",
    "    # retrieve API's name from apis_df\n",
    "    api_name = apis_df.iloc[i[0]][\"api\"]\n",
    "    cos_sim_score = i[1]\n",
    "    # append a tuple of API name and its cosine similarity score\n",
    "    recommendations.append((api_name, cos_sim_score))\n",
    "\n",
    "  api_name = apis_df.iloc[api_id][\"api\"]\n",
    "  print(\"The top \" + str(k) + \" recommended APIs and their cosine similarity score for \" + api_name + \" is:\\n\")\n",
    "\n",
    "  return recommendations\n",
    "\n",
    "# test recommendation\n",
    "recommend_apis(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
